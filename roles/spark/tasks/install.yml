- name: Check spark file
  stat: 
    path: "/tmp/spark-{{ spark_version }}-bin-hadoop2.7.tgz"
  register: downloaded

- name: Download spark
  get_url: 
    url: 'http://apache.mirror.amaze.com.au/spark/spark-{{ spark_version }}/spark-{{ spark_version }}-bin-hadoop2.7.tgz'
    dest: /tmp/
  when: downloaded.stat.exists == false

- name: Unpack spark source code
  unarchive: 
    src: "/tmp/spark-{{ spark_version }}-bin-hadoop2.7.tgz"
    dest: "{{ service_dir }}"
    remote_src: yes

- name: Add SPARK_HOME
  lineinfile:
    dest: /home/ubuntu/.bashrc
    insertafter: 'EOF'  
    line: 'export SPARK_HOME={{ service_dir }}/spark-{{ spark_version }}-bin-hadoop2.7'

- name: Add path
  lineinfile: 
    dest: /home/ubuntu/.bashrc
    insertafter: 'EOF'  
    line: 'export PATH="$PATH:{{ service_dir }}/spark-{{ spark_version }}-bin-hadoop2.7/bin"' 
    state: present

- name: Refresh .bashrc
  shell: source /home/ubuntu/.bashrc
  args: 
    executable: /bin/bash

- name: Generate spark-env.sh for spark
  template: 
    src: spark-env.j2 
    dest: "{{ service_dir }}/spark-{{ spark_version }}-bin-hadoop2.7/conf/spark-env.sh"
    owner: "{{ uusername }}"
    mode: 0644

- name: Generate hive-site.j2 for spark
  template: 
    src: hive-site.j2 
    dest: "{{ service_dir }}/spark-{{ spark_version }}-bin-hadoop2.7/conf/hive-site.xml"
    owner: "{{ uusername }}"
    mode: 0644

- name: Generate slaves for spark
  template: 
    src: workers.j2
    dest: "{{ service_dir }}/spark-{{ spark_version }}-bin-hadoop2.7/conf/slaves" 
    owner: "{{ uusername }}"
    mode: 0644

